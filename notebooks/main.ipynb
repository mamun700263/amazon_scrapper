{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T15:55:41.623483Z",
     "start_time": "2025-05-03T15:55:41.268088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries for web scraping, selenium, and pydantic validation\n",
    "import random, time, undetected_chromedriver as uc, os\n",
    "\n",
    "from typing import List, Optional, Union, Dict\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from pydantic import BaseModel, HttpUrl, Field\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from logger import logger\n",
    "from utils.common import save_as, soup_maker, load_and_scroll, pagination\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:18:36.741274113Z",
     "start_time": "2025-04-30T00:38:40.669851Z"
    }
   },
   "outputs": [],
   "source": [
    "class SearchProduct(BaseModel):\n",
    "    title: str = Field(..., min_length=3)\n",
    "    link: HttpUrl\n",
    "    image: Optional[HttpUrl]\n",
    "    price: Optional[float]\n",
    "    rating: Optional[float]\n",
    "    total_ratings: Optional[int]\n",
    "\n",
    "def pydentic_(results:List[Dict[str, str]]) -> List[SearchProduct]:\n",
    "    search_products = []\n",
    "    for result in results:\n",
    "        item = SearchProduct(\n",
    "            title=result[\"Title\"],\n",
    "            image=result[\"Image\"],\n",
    "            link=result[\"Link\"],\n",
    "            price=None,\n",
    "            rating=None,\n",
    "            total_ratings=None\n",
    "        )\n",
    "        search_products.append(item)\n",
    "        logger.info(f\"‚ÑπÔ∏è Product {item.title} successfully extracted\")\n",
    "    return search_products\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:18:36.770670810Z",
     "start_time": "2025-04-29T15:24:53.310822Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScraperConfig:\n",
    "    \"\"\"\n",
    "    Scraper configuration manager for initializing Selenium WebDriver instances.\n",
    "\n",
    "    This class supports various configurations such as:\n",
    "    - Headless mode\n",
    "    - Incognito mode\n",
    "    - Proxy configuration (ScrapeOps)\n",
    "    - SeleniumWire support\n",
    "    - Random User-Agent rotation\n",
    "\n",
    "    Attributes:\n",
    "        SCRAPEOPS_API_KEY (str): API key for ScrapeOps service.\n",
    "        use_uc (bool): Whether to use undetected_chromedriver (UC).\n",
    "        headless (bool): Whether to enable headless mode for the WebDriver.\n",
    "        incognito (bool): Whether to start the browser in incognito mode.\n",
    "        user_agent (Optional[str]): Custom User-Agent string for the WebDriver.\n",
    "        use_scrapeops (bool): Whether to use ScrapeOps proxy service.\n",
    "        use_seleniumwire (bool): Whether to use SeleniumWire for intercepting requests.\n",
    "        proxy (Optional[str]): Proxy URL for ScrapeOps (if applicable).\n",
    "        user_agents (List[str]): List of User-Agent strings for random rotation.\n",
    "        random_user_agent (str): A randomly selected or custom User-Agent string.\n",
    "        driver (Union[webdriver.Chrome, \"seleniumwire.webdriver.Chrome\", uc.Chrome]):\n",
    "            The initialized WebDriver instance.\n",
    "    \"\"\"\n",
    "\n",
    "    SCRAPEOPS_API_KEY: str =  os.getenv(\"SCRAPEOPS_API_KEY\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_uc: bool = False,\n",
    "        headless: bool = False,\n",
    "        incognito: bool = True,\n",
    "        user_agent: Optional[str] = None,\n",
    "        use_scrapeops: bool = False,\n",
    "        use_seleniumwire: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the ScraperConfig object with the given configuration parameters.\n",
    "\n",
    "        Args:\n",
    "            use_uc (bool): Whether to use undetected_chromedriver (UC).\n",
    "            headless (bool): Whether to run the browser in headless mode.\n",
    "            incognito (bool): Whether to run the browser in incognito mode.\n",
    "            user_agent (Optional[str]): Custom User-Agent to use.\n",
    "            use_scrapeops (bool): Whether to use ScrapeOps proxy service.\n",
    "            use_seleniumwire (bool): Whether to use SeleniumWire.\n",
    "\n",
    "        Initializes:\n",
    "            Sets the attributes based on the passed configuration.\n",
    "            Initializes the WebDriver according to the selected options.\n",
    "        \"\"\"\n",
    "        self.use_uc = use_uc\n",
    "        self.headless = headless\n",
    "        self.incognito = incognito\n",
    "        self.use_scrapeops = use_scrapeops\n",
    "        self.use_seleniumwire = use_seleniumwire\n",
    "\n",
    "        self.uc_options = uc.ChromeOptions()\n",
    "        self.chrome_options = ChromeOptions()\n",
    "\n",
    "        self.proxy = (\n",
    "            f\"http://scrapeops.headless_browser_mode=true:{self.SCRAPEOPS_API_KEY}@proxy.scrapeops.io:5353\"\n",
    "            if self.use_scrapeops else None\n",
    "        )\n",
    "\n",
    "\n",
    "        self.user_agents: List[str] = self._load_user_agents()\n",
    "        self.random_user_agent: str = (\n",
    "            user_agent or\n",
    "            random.choice(self.user_agents)\n",
    "        )\n",
    "\n",
    "        self.driver = self._init_driver()\n",
    "\n",
    "\n",
    "    def _init_driver(\n",
    "        self,\n",
    "    ) -> Union[webdriver.Chrome, \"seleniumwire.webdriver.Chrome\", uc.Chrome]:\n",
    "        \"\"\"\n",
    "        Initializes the appropriate driver based on the configuration.\n",
    "\n",
    "        Returns:\n",
    "            Union[webdriver.Chrome, seleniumwire.webdriver.Chrome, uc.Chrome]:\n",
    "            The configured WebDriver instance.\n",
    "\n",
    "        Notes:\n",
    "            This function selects the appropriate driver based on whether\n",
    "            undetected_chromedriver (UC) is enabled or a regular Chrome driver\n",
    "            is to be used, with or without SeleniumWire.\n",
    "        \"\"\"\n",
    "        if self.use_uc:\n",
    "            logger.info(\"‚öôÔ∏è Using undetected_chromedriver (UC)\")\n",
    "            return self._get_uc_driver()\n",
    "\n",
    "        logger.info(\"‚öôÔ∏è Using standard Chrome driver\")\n",
    "        return self._get_normal_driver()\n",
    "\n",
    "    def _get_uc_driver(self) -> uc.Chrome:\n",
    "        \"\"\"\n",
    "        Configures and returns an undetected_chromedriver (UC) instance.\n",
    "\n",
    "        Returns:\n",
    "            uc.Chrome: The configured undetected Chrome driver.\n",
    "\n",
    "        Notes:\n",
    "            This method configures the driver with additional stealth options\n",
    "            to avoid detection as a bot, such as disabling automation features.\n",
    "        \"\"\"\n",
    "        self._apply_common_options(self.uc_options)\n",
    "\n",
    "        # Additional stealth options for UC\n",
    "        self.uc_options.add_argument\\\n",
    "            (\"--disable-blink-features=AutomationControlled\")\n",
    "\n",
    "        return uc.Chrome(options=self.uc_options)\n",
    "\n",
    "    def _get_normal_driver(\n",
    "        self,\n",
    "    ) -> Union[webdriver.Chrome, \"seleniumwire.webdriver.Chrome\"]:\n",
    "        \"\"\"\n",
    "        Configures and returns a standard Chrome WebDriver.\n",
    "\n",
    "        Returns:\n",
    "            Union[webdriver.Chrome, seleniumwire.webdriver.Chrome]:\n",
    "            The configured normal Chrome driver.\n",
    "\n",
    "        Notes:\n",
    "            If SeleniumWire is enabled, this function configures the driver\n",
    "            with SeleniumWire proxy options for intercepting requests.\n",
    "        \"\"\"\n",
    "        self._apply_common_options(self.chrome_options)\n",
    "\n",
    "        if self.use_seleniumwire:\n",
    "            from seleniumwire import webdriver as wire_webdriver\n",
    "\n",
    "            seleniumwire_options = (\n",
    "                {\n",
    "                    \"proxy\": {\n",
    "                        \"http\": self.proxy,\n",
    "                        \"https\": self.proxy,\n",
    "                        \"no_proxy\": \"localhost,127.0.0.1\",\n",
    "                    }\n",
    "                }\n",
    "                if self.proxy\n",
    "                else {}\n",
    "            )\n",
    "\n",
    "            return wire_webdriver.Chrome(\n",
    "                options=self.chrome_options,\n",
    "                seleniumwire_options=seleniumwire_options\n",
    "            )\n",
    "\n",
    "        return webdriver.Chrome(\n",
    "            service=ChromeService(ChromeDriverManager().install()),\n",
    "            options=self.chrome_options,\n",
    "        )\n",
    "\n",
    "    def _apply_common_options(\n",
    "        self, options: Union[ChromeOptions, uc.ChromeOptions]\n",
    "    ) -> None:\n",
    "       \"\"\"\n",
    "        Applies common options for Chrome based on the current configuration.\n",
    "\n",
    "        Args:\n",
    "            options (Union[ChromeOptions, uc.ChromeOptions]):\n",
    "            The options object to configure.\n",
    "\n",
    "        This function adds configurations for:\n",
    "        - Headless mode\n",
    "        - Incognito mode\n",
    "        - Proxy settings (if any)\n",
    "        - Other browser performance-related settings\n",
    "        \"\"\"\n",
    "       if self.headless:\n",
    "           options.add_argument(\"--headless=new\")\n",
    "       if self.incognito:\n",
    "           options.add_argument(\"--incognito\")\n",
    "       if self.proxy:\n",
    "           options.add_argument(f\"--proxy-server={self.proxy}\")\n",
    "       options.add_argument(\"--no-sandbox\")\n",
    "       options.add_argument(\"--disable-dev-shm-usage\")\n",
    "       options.add_argument(\"--disable-popup-blocking\")\n",
    "       options.add_argument(\"--disable-infobars\")\n",
    "       options.add_argument(\"--start-maximized\")\n",
    "       options.add_argument(\"--window-size=1920,1080\")\n",
    "       options.add_argument(f\"user-agent={self.random_user_agent}\")\n",
    "\n",
    "\n",
    "    def _load_user_agents(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Loads a list of User-Agent strings.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of user-agent strings.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Linux; Android 14; SM-S918B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Mobile Safari/537.36\",\n",
    "            \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/17.0 Mobile Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0\",\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/122.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Firefox/120.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64; rv:120.0) Gecko/20100101 Firefox/120.0\",\n",
    "            \"Mozilla/5.0 (Linux; Android 14; SM-S918B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Mobile Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Linux; Android 13; Pixel 7 Pro) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Mobile Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Linux; Android 12; SM-G991B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Mobile Safari/537.36\",\n",
    "            \"Mozilla/5.0 (Android 13; Mobile; rv:120.0) Gecko/120.0 Firefox/120.0\",\n",
    "            \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (iPhone; CPU iPhone OS 16_5 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) CriOS/120.0.0.0 Mobile/15E148 Safari/537.36\",\n",
    "            \"Mozilla/5.0 (iPad; CPU OS 16_1 like Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Version/16.1 Mobile/15E148 Safari/537.36\"\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:18:36.793921747Z",
     "start_time": "2025-04-29T15:24:53.410096Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ProductExtractor:\n",
    "    def __init__(self, soup: BeautifulSoup, base_url: str):\n",
    "        self.soup = soup\n",
    "        self.base_url = base_url\n",
    "\n",
    "    def list_items(self) -> List[Tag]:\n",
    "        \"\"\"Locate all product list items from the soup.\"\"\"\n",
    "        try:\n",
    "            items = self.soup.select('div[role=\"listitem\"]') or []\n",
    "            logger.info(f\"‚úÖ Found {len(items)} product items\")\n",
    "            return items\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error locating list items: {e}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_text(item: Tag, selector: str, attr: str = None) -> str:\n",
    "        \"\"\"Extract text or attribute value from an HTML element.\"\"\"\n",
    "        try:\n",
    "            element = item.find(selector) or \"\"\n",
    "            return element.get(attr) if attr else element.text.strip()\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"‚ö†Ô∏è Extraction failed for selector '{selector}': {e}\")\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "    def extract_field(self, item: Tag, field_type: str) -> str:\n",
    "        \"\"\"Extract specific field (title, image, link) from product item.\"\"\"\n",
    "        field_selectors = {\n",
    "            'title': \"h2\",\n",
    "            'image': \"img\",\n",
    "            'link': \"a\"\n",
    "        }\n",
    "\n",
    "        attrs = {\n",
    "            'image': \"src\",\n",
    "            'link': \"href\",\n",
    "        }\n",
    "\n",
    "        selector = field_selectors.get(field_type)\n",
    "        attr = attrs.get(field_type)  # Will be None for title\n",
    "\n",
    "        if not selector:\n",
    "            logger.warning(f\"‚ö†Ô∏è Unknown field type: {field_type}\")\n",
    "            return \"\"\n",
    "\n",
    "        extracted = self.extract_text(item, selector, attr)\n",
    "\n",
    "        if field_type == 'link' and extracted:\n",
    "            return f\"{self.base_url}{extracted}\"\n",
    "        return extracted\n",
    "\n",
    "    def extract(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Main extraction logic.\"\"\"\n",
    "        if not self.soup:\n",
    "            logger.error(\"‚ùå No soup provided to extractor\")\n",
    "            return []\n",
    "\n",
    "        items = self.list_items()\n",
    "        results = []\n",
    "\n",
    "        for item in items:\n",
    "            title = self.extract_field(item, 'title')\n",
    "            if not title:\n",
    "                continue  # Skip items with no title\n",
    "\n",
    "            product = {\n",
    "                \"Title\": title,\n",
    "                \"Image\": self.extract_field(item, 'image'),\n",
    "                \"Link\": self.extract_field(item, 'link'),\n",
    "            }\n",
    "            logger.debug(f\"üìù Product extracted: {title}\")\n",
    "            results.append(product)\n",
    "\n",
    "        logger.info(f\"‚úÖ Extracted {len(results)} products successfully\")\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:18:36.795114548Z",
     "start_time": "2025-04-29T15:24:53.459361Z"
    }
   },
   "outputs": [],
   "source": [
    "class AmazonScraper:\n",
    "    def __init__(self, config: ScraperConfig):\n",
    "        self.config = config\n",
    "        self.driver = config.driver\n",
    "        self.url = \"https://www.amazon.com\"\n",
    "        logger.info(\"üöÄ AmazonScraper initialized\")\n",
    "\n",
    "    def get_search_url(self, keyword: str) -> str:\n",
    "        encoded = quote_plus(keyword)\n",
    "        search_url = f\"{self.url}/s?k={encoded}\"\n",
    "        logger.debug(f\"üîó Generated search URL: {search_url}\")\n",
    "        return search_url\n",
    "\n",
    "    def scrape_search_results(self, keyword: str, wait_time: int=3) -> str:\n",
    "        url = self.get_search_url(keyword)\n",
    "        logger.info(f\"üåê Navigating to search page: {url}\")\n",
    "        try:\n",
    "            load_and_scroll(self.driver,url)\n",
    "            logger.info(\"‚úÖ Page loaded and ready for scraping\")\n",
    "            return self.driver.page_source\n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Error loading page for keyword '{keyword}': {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def scrape_all_pages(self, keyword: str, max_pages=5)-> List[Dict[str, str]]:\n",
    "        results = []\n",
    "        response = self.scrape_search_results(keyword)\n",
    "        soup = soup_maker(response)\n",
    "        page = 0\n",
    "        amazon_extractor = ProductExtractor(soup,self.url)\n",
    "\n",
    "        while soup and page < max_pages: #apply retry here\n",
    "            data = amazon_extractor.extract()\n",
    "            results += data\n",
    "\n",
    "            logger.info(f\"üìÑ Page {page + 1} scraped.\")\n",
    "\n",
    "            next_page_url = pagination(soup,self.url)\n",
    "            # next_page_url = next_page_url[:-1]+(next_page_url[-1]+1)\n",
    "            if not next_page_url:\n",
    "                break\n",
    "\n",
    "            self.driver.get(next_page_url)\n",
    "            time.sleep(random.uniform(2, 4))  # can swap with sleeper()\n",
    "            soup = soup_maker(self.driver.page_source)\n",
    "            page += 1\n",
    "\n",
    "        return results\n",
    "\n",
    "    def quit(self):\n",
    "        logger.info(\"üõë Quitting WebDriver\")\n",
    "        self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:18:36.799646115Z",
     "start_time": "2025-04-29T15:24:53.518440Z"
    }
   },
   "outputs": [],
   "source": [
    "config = ScraperConfig()\n",
    "amazon = AmazonScraper(config)\n",
    "driver = amazon.driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:18:36.801000181Z",
     "start_time": "2025-04-29T15:24:54.647658Z"
    }
   },
   "outputs": [],
   "source": [
    "results = amazon.scrape_all_pages(\"32 gb ram\", max_pages=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pydentic_(results:List[Dict[str, str]]) -> List[SearchProduct]:\n",
    "    search_products = []\n",
    "    for result in results:\n",
    "        item = SearchProduct(\n",
    "            title=result[\"Title\"],\n",
    "            image=result[\"Image\"],\n",
    "            link=result[\"Link\"],\n",
    "            price=None,\n",
    "            rating=None,\n",
    "            total_ratings=None\n",
    "        )\n",
    "        search_products.append(item)\n",
    "        logger.info(f\"‚ÑπÔ∏è Product {item.title} successfully extracted\")\n",
    "    return search_products\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:18:36.801749413Z",
     "start_time": "2025-04-30T00:42:25.065347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='„ÄêRGB DDR4 RAM„ÄëGIGASTONE Game TURBO 32GB Kit (2x16GB)DDR4 3200MHz PC4-25600 CL16-18-18-40 Intel XMP 2.0 AMD Ryzen 1.35V UDIMM 288 Pin Unbuffered Non ECC High Performance Gaming Desktop Memory - Black' link=HttpUrl('https://www.amazon.com/sspa/click?ie=UTF8&spc=MTo0MDA4NDI4NjQ4NjU1MzUyOjE3NDU5NDAyOTU6c3BfYXRmOjMwMDczOTY2NDU4ODcwMjo6MDo6&url=%2FGIGASTONE-Desktop-DDR4-3200MHz-PC4-25600-Unbuffered%2Fdp%2FB0CB2VGYFW%2Fref%3Dsr_1_1_sspa%3Fdib%3DeyJ2IjoiMSJ9.tw7-N2U1w1gwJjC2CkCPw641JRVXa83WrGdQPf5HIjxWiXIHS2ItFhikmEjMXmkzUh1zw154zCgV1rxT2AeCPbys5hk-js3_N6sAIdaySTaMrtvpckyzB8GPuO87-8oRCqAIrzUdXnmg8j1diWHWKSTMqAw6jT9_UyorKq_GufwjbJpyFU5k02obR2BCBOoXEyC3JpgaS7-LmiUjBiEEpBIw6uRYDVsEIDo-gmPyHpw.TzgiXiQugmV_whUPhnA3v21gYEQVVWqDLC3kLVxKtHA%26dib_tag%3Dse%26keywords%3D32%2Bgb%2Bram%26qid%3D1745940295%26sr%3D8-1-spons%26sp_csd%3Dd2lkZ2V0TmFtZT1zcF9hdGY%26psc%3D1') image=HttpUrl('https://m.media-amazon.com/images/I/510V6PbPGrL._AC_UY218_.jpg') price=None rating=None total_ratings=None\n",
      "title='„ÄêDDR4 RAM„Äë GIGASTONE Game PRO 32GB Kit (2x16GB) DDR4 3200MHz PC4-25600 CL 16-18-18-40 Intel XMP 2.0 AMD Ryzen 1.35V UDIMM 288 Pin Unbuffered Non ECC High Performance Gaming Desktop Memory - White' link=HttpUrl('https://www.amazon.com/sspa/click?ie=UTF8&spc=MTo0MDA4NDI4NjQ4NjU1MzUyOjE3NDU5NDAyOTU6c3BfYXRmOjMwMDU4MjkyNTQ1MjUwMjo6MDo6&url=%2FGIGASTONE-Desktop-DDR4-3200MHz-PC4-25600-Unbuffered%2Fdp%2FB0CB2TZKCG%2Fref%3Dsr_1_2_sspa%3Fdib%3DeyJ2IjoiMSJ9.tw7-N2U1w1gwJjC2CkCPw641JRVXa83WrGdQPf5HIjxWiXIHS2ItFhikmEjMXmkzUh1zw154zCgV1rxT2AeCPbys5hk-js3_N6sAIdaySTaMrtvpckyzB8GPuO87-8oRCqAIrzUdXnmg8j1diWHWKSTMqAw6jT9_UyorKq_GufwjbJpyFU5k02obR2BCBOoXEyC3JpgaS7-LmiUjBiEEpBIw6uRYDVsEIDo-gmPyHpw.TzgiXiQugmV_whUPhnA3v21gYEQVVWqDLC3kLVxKtHA%26dib_tag%3Dse%26keywords%3D32%2Bgb%2Bram%26qid%3D1745940295%26sr%3D8-2-spons%26sp_csd%3Dd2lkZ2V0TmFtZT1zcF9hdGY%26psc%3D1') image=HttpUrl('https://m.media-amazon.com/images/I/51BM392zpdL._AC_UY218_.jpg') price=None rating=None total_ratings=None\n",
      "title='CORSAIR VENGEANCE LPX DDR4 RAM 32GB (2x16GB) 3200MHz CL16-20-20-38 1.35V Intel AMD Desktop Computer Memory - Black (CMK32GX4M2E3200C16)' link=HttpUrl('https://www.amazon.com/Corsair-VENGEANCE-3200MHz-Compatible-Computer/dp/B07RW6Z692/ref=sr_1_3?dib=eyJ2IjoiMSJ9.tw7-N2U1w1gwJjC2CkCPw641JRVXa83WrGdQPf5HIjxWiXIHS2ItFhikmEjMXmkzUh1zw154zCgV1rxT2AeCPbys5hk-js3_N6sAIdaySTaMrtvpckyzB8GPuO87-8oRCqAIrzUdXnmg8j1diWHWKSTMqAw6jT9_UyorKq_GufwjbJpyFU5k02obR2BCBOoXEyC3JpgaS7-LmiUjBiEEpBIw6uRYDVsEIDo-gmPyHpw.TzgiXiQugmV_whUPhnA3v21gYEQVVWqDLC3kLVxKtHA&dib_tag=se&keywords=32+gb+ram&qid=1745940295&sr=8-3') image=HttpUrl('https://m.media-amazon.com/images/I/61wCOVcyvFL._AC_UY218_.jpg') price=None rating=None total_ratings=None\n",
      "title='Computer Desktop Memory Ram DDR4 32GB(2x16GB) 3200MHZ CL16 1.35V XMP2.0 Overclocking with Heatsink for PC Gaming/Office/PS,Silver' link=HttpUrl('https://www.amazon.com/KingBank-Computer-Desktop-3200MHZ-Heatsink/dp/B0DF7M23ST/ref=sr_1_4?dib=eyJ2IjoiMSJ9.tw7-N2U1w1gwJjC2CkCPw641JRVXa83WrGdQPf5HIjxWiXIHS2ItFhikmEjMXmkzUh1zw154zCgV1rxT2AeCPbys5hk-js3_N6sAIdaySTaMrtvpckyzB8GPuO87-8oRCqAIrzUdXnmg8j1diWHWKSTMqAw6jT9_UyorKq_GufwjbJpyFU5k02obR2BCBOoXEyC3JpgaS7-LmiUjBiEEpBIw6uRYDVsEIDo-gmPyHpw.TzgiXiQugmV_whUPhnA3v21gYEQVVWqDLC3kLVxKtHA&dib_tag=se&keywords=32+gb+ram&qid=1745940295&sr=8-4') image=HttpUrl('https://m.media-amazon.com/images/I/61jSWw3xpyL._AC_UY218_.jpg') price=None rating=None total_ratings=None\n"
     ]
    }
   ],
   "source": [
    "search_products = pydentic_(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:18:36.802187711Z",
     "start_time": "2025-04-29T15:25:17.467930Z"
    }
   },
   "outputs": [],
   "source": [
    "save_as(items=results, file_name=\"first.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T12:18:36.802563775Z",
     "start_time": "2025-04-29T15:25:17.526893Z"
    }
   },
   "outputs": [],
   "source": [
    "amazon.quit()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
